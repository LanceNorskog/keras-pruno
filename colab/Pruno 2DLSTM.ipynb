{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pruno 2DLSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOlpRpGx+eEmGPIXgBIdZCs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mYEme093tkZ_"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"gSkMjCBItiDN"},"source":["!pip install -q tensorflow==2.4.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tAqsqB8diZWO"},"source":[""]},{"cell_type":"code","metadata":{"id":"KOTJoBpCtq2q"},"source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.python.framework import smart_cond\n","\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0KaPBGk6TFr"},"source":["# try:\n","#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","#     print(\"Device:\", tpu.master())\n","#     tf.config.experimental_connect_to_cluster(tpu)\n","#     tf.tpu.experimental.initialize_tpu_system(tpu)\n","#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","# except:\n","#     strategy = tf.distribute.get_strategy()\n","# print(\"Number of replicas:\", strategy.num_replicas_in_sync)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4s7YNs6h9oG"},"source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.python.framework import smart_cond\n","\n","import numpy as np\n","\n","def pruno_random_channels_first(similarity, seed, inputs_flat, actual_batchsize, fmap_count, fmap_size):\n","    fmap_even = (fmap_count//2)*2\n","    flatshape = (-1, fmap_count, fmap_size)\n","    gam = tf.math.reduce_mean(inputs_flat, axis=-1, keepdims=True)\n","    live = tf.cast(inputs_flat[:, :, :] > gam[:, :, :], dtype='float32', name='live')\n","    indices = tf.constant(np.arange(fmap_count), dtype='int32')\n","    random_indices = tf.random.shuffle(indices, seed=seed)\n","    mult_list = []\n","    for fm in range(0, fmap_even, 2):\n","        mult_list.append(live[:, random_indices[fm], :] * live[:, random_indices[fm + 1], :])\n","    mult = tf.stack(mult_list, axis=1, name='stack1')\n","    percent = tf.math.reduce_sum(mult, axis=-1, keepdims=True, name='percent') / flatshape[2]\n","    mask = tf.cast(percent < similarity, dtype='float32', name='mask')\n","    mask_unstack = tf.unstack(mask, axis=1, name='unstack1')\n","    mask_list = []\n","    for i in range(fmap_even // 2):\n","        mask_list.append(mask_unstack[i])\n","        mask_list.append(mask_unstack[i])\n","    if fmap_count > fmap_even:\n","        mask_list.append(tf.ones_like(mask_unstack[0], dtype='float32'))\n","    dup_mask = tf.stack(mask_list, axis=1, name='stack2')\n","    tiled_indices_flat = tf.tile(random_indices, actual_batchsize)\n","    tiled_indices = tf.reshape(tiled_indices_flat, (-1, flatshape[1], 1))\n","    inverse_mask_flat = tf.gather(dup_mask, tiled_indices, batch_dims=1, axis=1)\n","    inverse_mask = tf.reshape(inverse_mask_flat, (-1, fmap_count, 1))\n","    return inputs_flat * inverse_mask\n","\n","def pruno_random_channels_last(similarity, seed, inputs_flat, actual_batchsize, fmap_count, fmap_size):\n","    fmap_even = (fmap_count//2)*2\n","    flatshape = (-1, fmap_size, fmap_count)\n","    gam = tf.math.reduce_mean(inputs_flat, axis=1, keepdims=True)\n","    live = tf.cast(inputs_flat[:, :, :] > gam[:, :, :], dtype='float32')\n","    indices = tf.constant(np.arange(fmap_count), dtype='int32')\n","    random_indices = tf.random.shuffle(indices, seed=seed)\n","    mult_list = []\n","    for fm in range(0, fmap_even, 2):\n","        mult_list.append(live[:, :, random_indices[fm]] * live[:, :, random_indices[fm + 1]])\n","    mult = tf.stack(mult_list, axis=2)\n","    percent = tf.math.reduce_sum(mult, axis=1, keepdims=True) / flatshape[1]\n","    mask = tf.cast(percent < similarity, dtype='float32')\n","    mask_unstack = tf.unstack(mask, axis=2)\n","    mask_list = []\n","    for i in range(fmap_even // 2):\n","        mask_list.append(mask_unstack[i])\n","        mask_list.append(mask_unstack[i])\n","    if fmap_even < fmap_count:\n","        mask_list.append(tf.ones_like(mask_unstack[0], dtype='float32'))\n","    dup_mask = tf.stack(mask_list, axis=1)\n","    tiled_indices_flat = tf.tile(random_indices, actual_batchsize)\n","    tiled_indices = tf.reshape(tiled_indices_flat, (-1, 1, fmap_count))\n","    inverse_mask_flat = tf.gather(dup_mask, tiled_indices, batch_dims=1, axis=1)\n","    inverse_mask = tf.reshape(inverse_mask_flat, (-1, 1, fmap_count))\n","    return inputs_flat * inverse_mask\n","\n","def pruno_random_channels_batchwise(similarity, seed, inputs_flat, actual_batchsize, fmap_count, fmap_size):\n","    fmap_even = (fmap_count//2)*2\n","    flatshape = (-1, fmap_size, fmap_count)\n","    gam = tf.math.reduce_mean(inputs_flat, axis=1, keepdims=True)\n","    live = tf.cast(inputs_flat[:, :, :] > gam[:, :, :], dtype='float32')\n","    indices = tf.constant(np.arange(fmap_count), dtype='int32')\n","    random_indices = tf.random.shuffle(indices, seed=seed)\n","    print('random_indices:', random_indices)\n","    mult_list = []\n","    for fm in range(0, fmap_even, 2):\n","        mult_list.append(live[:, :, random_indices[fm]] * live[:, :, random_indices[fm + 1]])\n","    mult = tf.stack(mult_list, axis=2)\n","    percent = tf.math.reduce_sum(mult, axis=1, keepdims=True) / flatshape[1]\n","    mask = tf.cast(percent < similarity, dtype='float32')\n","    print('mask:', mask)\n","    # return mask\n","    mean_mask = tf.cast(tf.math.reduce_mean(mask, axis=0) > 0.50001, dtype='float32')\n","    mean_mask = tf.tile(tf.squeeze(mean_mask), actual_batchsize)\n","    mean_mask = tf.reshape(mean_mask, (-1, 1, fmap_even // 2))\n","    print('mean_mask:', mean_mask)\n","    # return mean_mask\n","    mask_unstack = tf.unstack(mean_mask, axis=2)\n","    mask_list = []\n","    for i in range(fmap_even // 2):\n","        mask_list.append(mask_unstack[i])\n","        mask_list.append(mask_unstack[i])\n","    if fmap_even < fmap_count:\n","        mask_list.append(tf.ones_like(mask_unstack[0], dtype='float32'))\n","    dup_mask = tf.stack(mask_list, axis=1)\n","    print('dup_mask:', dup_mask)\n","    # return dup_mask\n","    tiled_indices_flat = tf.tile(random_indices, actual_batchsize)\n","    tiled_indices = tf.reshape(tiled_indices_flat, (-1, 1, fmap_count))\n","    print('tiled_indices:', tiled_indices)\n","    # return tiled_indices\n","    inverse_mask_flat = tf.gather(dup_mask, tiled_indices, batch_dims=1, axis=1)\n","    inverse_mask = tf.reshape(inverse_mask_flat, (-1, 1, fmap_count))\n","    return inputs_flat * inverse_mask\n","\n","def pruno_random_channels_norm_batchwise(similarity, seed, inputs_flat, actual_batchsize, fmap_count, fmap_size, batchwise=True):\n","    fmap_even = (fmap_count//2)*2\n","    flatshape = (-1, fmap_size, fmap_count)\n","    indices = tf.constant(np.arange(fmap_count), dtype='int32')\n","    random_indices = tf.random.shuffle(indices, seed=seed)\n","    # print('random_indices:', random_indices)\n","    inputs_norm, inputs_norm_sqrt = tf.linalg.normalize(inputs_flat, axis=1)\n","    # print('inputs_norm:', inputs_norm)\n","    # return inputs_norm\n","    mult_list = []\n","    for fm in range(0, fmap_even, 2):\n","        mult_list.append(inputs_norm[:, :, random_indices[fm]] * inputs_norm[:, :, random_indices[fm + 1]])\n","    mult = tf.stack(mult_list, axis=2)\n","\n","    gam = tf.math.reduce_mean(mult, axis=1, keepdims=True)\n","    # print('gam:', gam)\n","    # return gam\n","    live = tf.cast(mult[:, :, :] > gam, dtype='float32')\n","    # print('live:', live)\n","    # return live\n","    percent = tf.math.reduce_sum(live, axis=1, keepdims=True) / flatshape[1]\n","    # print('percent:', percent)\n","    # return percent\n","    mask = tf.cast(percent < similarity, dtype='float32')\n","    # print('mask:', mask)\n","    # return mask\n","    if batchwise:\n","        mask = tf.cast(tf.math.reduce_mean(mask, axis=0) > 0.50001, dtype='float32')\n","        # I have no idea why these two variations are necessary\n","        if fmap_count > 3:\n","            mask = tf.squeeze(mask)\n","        else:\n","            mask = tf.reshape(mask, (1,))\n","        mask = tf.tile(mask, actual_batchsize)\n","        mask = tf.reshape(mask, (-1, 1, fmap_even // 2))\n","        print('batchwise')\n","    else:\n","        print('not batchwise')\n","    mask_unstack = tf.unstack(mask, axis=2)\n","    mask_list = []\n","    for i in range(fmap_even // 2):\n","        mask_list.append(mask_unstack[i])\n","        mask_list.append(mask_unstack[i])\n","    if fmap_even < fmap_count:\n","        mask_list.append(tf.ones_like(mask_unstack[0], dtype='float32'))\n","    dup_mask = tf.stack(mask_list, axis=1)\n","    # print('dup_mask:', dup_mask)\n","    # return dup_mask\n","    tiled_indices_flat = tf.tile(random_indices, actual_batchsize)\n","    tiled_indices = tf.reshape(tiled_indices_flat, (-1, 1, fmap_count))\n","    # print('tiled_indices:', tiled_indices)\n","    # return tiled_indices\n","    inverse_mask_flat = tf.gather(dup_mask, tiled_indices, batch_dims=1, axis=1)\n","    inverse_mask = tf.reshape(inverse_mask_flat, (-1, 1, fmap_count))\n","    # print('inverse_mask:', inverse_mask)\n","    # return inverse_mask\n","    return inputs_flat * inverse_mask\n","\n","class Pruno2DLSTM(tf.keras.layers.Layer):\n","    \"\"\"Applies Pruning Dropout to the input.\n","    \n","    Conv2DLSTM output: (batch, time, row, col, fmaps)\n","    \n","    The Pruno2DLSTM layer compares randomly chosen pairs of feature maps, and sets\n","    both feature maps to zero when they are \"too similar\". Similarity is measured\n","    by counting the pixels in both feature maps that are greater than the mean \n","    of each feature map.\n","    When using `model.fit`,\n","    `training` will be appropriately set to True automatically, and in other\n","    contexts, you can set the kwarg explicitly to True when calling the layer.\n","    (This is in contrast to setting `trainable=False` for a Pruno layer.\n","    `trainable` does not affect the layer's behavior, as Pruno does\n","    not have any variables/weights that can be frozen during training.)\n","    >>> layer = Pruno(.2, seed=0, input_shape=(2, 5, 2))\n","    >>> data = np.arange(20).reshape(2, 5, 2).astype(np.float32)\n","    >>> print(data)\n","    [[[ 0.  1.]\n","    [ 2.  3.]\n","    [ 4.  5.]\n","    [ 6.  7.]\n","    [ 8.  9.]]\n","  \n","   [[10. 11.]\n","    [12. 13.]\n","    [14. 15.]\n","    [16. 17.]\n","    [18. 19.]]]\n","    >>> outputs = layer(data, training=True)\n","    >>> print(outputs)\n","    tf.Tensor(\n","    [[ 0.    1.25]\n","     [ 2.5   3.75]\n","     [ 5.    6.25]\n","     [ 7.5   8.75]\n","     [10.    0.  ]], shape=(5, 2), dtype=float32)\n","    Arguments:\n","      rate: Float between 0 and 1. 1.0 - rate = percentage of matching values \n","      which triggers a dropout event\n","      seed: A Python integer to use as random seed.\n","    Call arguments:\n","      inputs: Input tensor (of any rank).\n","      training: Python boolean indicating whether the layer should behave in\n","        training mode (adding dropout) or in inference mode (doing nothing).\n","    \"\"\"\n","  \n","    def __init__(self, similarity, batchwise=True, norm=False, sequence=True, seed=None, training=False, **kwargs):\n","        super(Pruno2DLSTM, self).__init__(**kwargs)\n","        if similarity < 0.0 or similarity > 1.0:\n","            raise ValueError('similarity must be between 0.0 and 1.0: %s' % str(similarity))\n","        self.similarity = similarity\n","        self.seed = seed\n","        self.batchwise = batchwise\n","        self.norm = norm\n","        self.sequence = sequence\n","        self.supports_masking = True\n","        self.training = training\n","        print('__init__: similarity:', similarity)\n","  \n","    def build(self, input_shape):\n","        print('Pruno2DLSTM.build: input_shape:', input_shape)\n","        self.built = True\n","  \n","    def call(self, inputs, training=None):\n","        if training is None:\n","            # do not activate in untrainable section of trainable model\n","            if self.training or self.trainable:\n","                training = K.learning_phase()\n","            else:\n","                training = False\n","        \n","        def identity_inputs():\n","            return inputs\n","  \n","        # each timestep is a separate batch\n","        # transpose to make timesteps * fmaps the final dimension\n","        def dropped_inputs():\n","            shape = inputs.shape.as_list()\n","            print('Pruno2DLSTM.call: shape as_list:', shape)\n","            actual_batchsize = tf.shape(inputs)[0:1]\n","            timesteps = shape[1]\n","            print('actual_batchsize, timesteps:', actual_batchsize, timesteps)\n","            self.fmap_shape = [shape[2], shape[3]]\n","            self.fmap_count = shape[4]\n","            if sequence:\n","                pass\n","            else:\n","                transposed = tf.transpose(inputs, perm=(0,2,3,1,4))\n","                print('transposed:', transposed)\n","                flatshape = (-1, self.fmap_shape[0] * self.fmap_shape[1], timesteps * self.fmap_count)\n","                print('flatshape:', flatshape)\n","                inputs_flatmap = tf.reshape(transposed, flatshape)\n","            if self.norm:\n","                outputs_flat = pruno_random_channels_norm_batchwise(self.similarity, self.seed, inputs_flatmap, actual_batchsize, \n","                                 flatshape[2], flatshape[1], batchwise=self.batchwise)\n","            elif self.batchwise:\n","                outputs_flat = pruno_random_channels_batchwise(self.similarity, self.seed, inputs_flatmap, actual_batchsize, \n","                                 flatshape[2], flatshape[1])\n","            else:\n","                outputs_flat = pruno_random_channels_last(self.similarity, self.seed, inputs_flatmap, actual_batchsize, \n","                                 flatshape[2], flatshape[1])\n","            if sequence:\n","                pass\n","            else:\n","                out_shape = (-1, self.fmap_shape[0], self.fmap_shape[1], timesteps, self.fmap_count)\n","                print('out_shape:', out_shape)\n","                out_reshaped = tf.reshape(outputs_flat, out_shape)\n","                print('output reshaped:', transposed)\n","                out_trans = tf.transpose(out_reshaped, perm=(0,3,1,2,4))\n","                print('output transposed:', out_trans)\n","                outputs = tf.reshape(out_trans, tf.shape(inputs))\n","            return outputs\n","  \n","        output = smart_cond.smart_cond(training, dropped_inputs,\n","                                            identity_inputs)\n","        return output\n","  \n","    # why?\n","    def _get_noise_shape(self, inputs):\n","        input_shape = array_ops.shape(inputs)\n","        noise_shape = (input_shape[0], 1, 1, 1, 1)\n","        return noise_shape\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","  \n","    def get_config(self):\n","        config = {\n","            'similarity': self.similarity,\n","            'batchwise': self.batchwise,\n","            'norm': self.norm,\n","            'seed': self.seed\n","        }\n","        base_config = super(Pruno2DLSTM, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXBwcIf_nmUc"},"source":["def get_model_LSTM(similarity, input_shape):\n","    input = tf.keras.Input(shape=input_shape)\n","    x = tf.keras.layers.ConvLSTM2D(11,1, return_sequences=True)(input)\n","    print('convlstm2d:', x)\n","    x = Pruno2DLSTM(similarity=0.46)(x) # , input_shape=input_shape, training=True)(x)\n","    x = tf.keras.layers.Conv3D(\n","            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n","        )(x),\n","    model = tf.keras.Model(input, x)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n","    model.summary()\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmMS21IGm8hN","executionInfo":{"status":"ok","timestamp":1619234981282,"user_tz":420,"elapsed":8323,"user":{"displayName":"Lance N.","photoUrl":"","userId":"10641691903871358793"}},"outputId":"22ed7a9a-4fc3-42be-b4ae-d43ab3b7a6d8"},"source":["# Example\n","in_data = np.arange(7*3*5*2).reshape((1, 7, 3, 5, 2)).astype(np.float32)\n","out_data = np.arange(7*3*5*1).reshape((1, 7, 3, 5, 1)).astype(np.float32)\n","#pruno = Pruno2DLSTM(similarity=0.46, input_shape=(7,3,5,2))\n","\n","model = get_model_LSTM(0.65, (7, 3,5,2))\n","model.fit(in_data, out_data, epochs=1)\n","# model.predict(data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["convlstm2d: KerasTensor(type_spec=TensorSpec(shape=(None, 7, 3, 5, 11), dtype=tf.float32, name=None), name='conv_lst_m2d_9/transpose_1:0', description=\"created by layer 'conv_lst_m2d_9'\")\n","__init__: similarity: 0.46\n","Pruno2DLSTM.build: input_shape: (None, 7, 3, 5, 11)\n","Model: \"model_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_10 (InputLayer)        [(None, 7, 3, 5, 2)]      0         \n","_________________________________________________________________\n","conv_lst_m2d_9 (ConvLSTM2D)  (None, 7, 3, 5, 11)       616       \n","_________________________________________________________________\n","pruno2dlstm_5 (Pruno2DLSTM)  (None, 7, 3, 5, 11)       0         \n","_________________________________________________________________\n","conv3d_3 (Conv3D)            (None, 7, 3, 5, 1)        298       \n","=================================================================\n","Total params: 914\n","Trainable params: 914\n","Non-trainable params: 0\n","_________________________________________________________________\n","Pruno2DLSTM.call: shape as_list: [None, 7, 3, 5, 11]\n","actual_batchsize, timesteps: Tensor(\"model_9/pruno2dlstm_5/strided_slice:0\", shape=(1,), dtype=int32) 7\n","transposed: Tensor(\"model_9/pruno2dlstm_5/transpose:0\", shape=(None, 3, 5, 7, 11), dtype=float32)\n","flatshape: (-1, 15, 77)\n","random_indices: Tensor(\"model_9/pruno2dlstm_5/RandomShuffle:0\", shape=(77,), dtype=int32)\n","mask: Tensor(\"model_9/pruno2dlstm_5/Cast_1:0\", shape=(None, 1, 38), dtype=float32)\n","mean_mask: Tensor(\"model_9/pruno2dlstm_5/Reshape_1:0\", shape=(None, 1, 38), dtype=float32)\n","dup_mask: Tensor(\"model_9/pruno2dlstm_5/stack_1:0\", shape=(None, 77, 1), dtype=float32)\n","tiled_indices: Tensor(\"model_9/pruno2dlstm_5/Reshape_2:0\", shape=(None, 1, 77), dtype=int32)\n","out_shape: (-1, 3, 5, 7, 11)\n","output reshaped: Tensor(\"model_9/pruno2dlstm_5/transpose:0\", shape=(None, 3, 5, 7, 11), dtype=float32)\n","output transposed: Tensor(\"model_9/pruno2dlstm_5/transpose_1:0\", shape=(None, 7, 3, 5, 11), dtype=float32)\n","Pruno2DLSTM.call: shape as_list: [None, 7, 3, 5, 11]\n","actual_batchsize, timesteps: Tensor(\"model_9/pruno2dlstm_5/strided_slice:0\", shape=(1,), dtype=int32) 7\n","transposed: Tensor(\"model_9/pruno2dlstm_5/transpose:0\", shape=(None, 3, 5, 7, 11), dtype=float32)\n","flatshape: (-1, 15, 77)\n","random_indices: Tensor(\"model_9/pruno2dlstm_5/RandomShuffle:0\", shape=(77,), dtype=int32)\n","mask: Tensor(\"model_9/pruno2dlstm_5/Cast_1:0\", shape=(None, 1, 38), dtype=float32)\n","mean_mask: Tensor(\"model_9/pruno2dlstm_5/Reshape_1:0\", shape=(None, 1, 38), dtype=float32)\n","dup_mask: Tensor(\"model_9/pruno2dlstm_5/stack_1:0\", shape=(None, 77, 1), dtype=float32)\n","tiled_indices: Tensor(\"model_9/pruno2dlstm_5/Reshape_2:0\", shape=(None, 1, 77), dtype=int32)\n","out_shape: (-1, 3, 5, 7, 11)\n","output reshaped: Tensor(\"model_9/pruno2dlstm_5/transpose:0\", shape=(None, 3, 5, 7, 11), dtype=float32)\n","output transposed: Tensor(\"model_9/pruno2dlstm_5/transpose_1:0\", shape=(None, 7, 3, 5, 11), dtype=float32)\n","1/1 [==============================] - 5s 5s/step - loss: -4.0853\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1028ee93d0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"ZtsUQh2LGqzL"},"source":["\n","\n","def get_model(similarity, input_shape):\n","    pruno = Pruno2D(similarity, input_shape)#, seed=0)\n","    model = tf.keras.models.Sequential(pruno)\n","    model.compile()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0E7yXlgRH6_G"},"source":["# Example\n","data = np.arange(30).reshape(1, 3, 5, 2).astype(np.float32)\n","pruno = Pruno2D(similarity=0.46, input_shape=(3,5,2))\n","model = tf.keras.models.Sequential(pruno,)\n","model.compile()\n","model.predict(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZbX5ucPvc4J"},"source":["# 3 5x3 feature maps\n","fmaps = 2\n","shape = (5, 4)\n","samples = 2\n","quant = shape[0]*shape[1]\n","zeros = np.zeros(((1,) + shape + (fmaps,)))\n","data = np.zeros(((samples,) + shape + (fmaps,)))\n","data1 = np.arange(quant).reshape(1, shape[0], shape[1], 1).astype(np.float32)/quant\n","data1 = data1 * 1.58\n","data[0, :, :, :] = data1 \n","data[1, :, :, :] = np.sin(data1)\n","# data[1, :, :, :] = data1 + 1\n","# data[2, :, :, :] = data1 + 2\n","\n","# data[0, 1, :, :] = np.sin(data1)\n","# data[0, 1, :, 0] = zeros[0, 0, :, 0]\n","# data[0, 1, :, 0:2] = zeros[0, 0, :, 0:2]\n","\n","print('data.shape:', data.shape)\n","\n","    # same, sim (.466 -> 4.67)\n","# 1/3 0, (0.333 -> 0.334) \n","pruno = Pruno2D(similarity=0.5, input_shape=(shape+(fmaps,)))\n","model = tf.keras.models.Sequential(pruno,)\n","model.compile()\n","model.predict(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bHmJjbKuErt"},"source":["# 4 5x3 feature maps\n","samples = 1\n","shape = (5, 3)\n","fmaps = 2\n","quant = shape[0] * shape[1]\n","data = np.zeros(((samples,) + shape + (fmaps,))) + 0.1\n","data1 = np.arange(quant).reshape((1, shape[0], shape[1], 1)).astype(np.float32)/quant\n","# data1 = data1 * 1.58\n","for i in range(samples-2):\n","    data[i, :, :, :] = data1[:, :, :, :]\n","    data[i, 0, :, 1] = np.sin(data1[:, 0, :, 0])\n","    data[i, 0, :, 2] = 0\n","    # data[i, 0:2, :, 3] = 0\n","\n","print('data.shape:', data.shape)\n","\n","# with strategy.scope():\n","model = get_model(similarity=0.5, input_shape=(shape + (fmaps,)))\n","\n","pred = model.predict(data)\n","print('pred.shape:', pred.shape)\n","print(pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9pREWxqgHQX"},"source":["# 4 5x3 feature maps\n","samples = 6\n","shape = (5, 3)\n","fmaps = 4\n","quant = shape[0] * shape[1]\n","data = np.zeros(((samples,) + shape + (fmaps,))) + 0.1\n","data1 = np.arange(quant).reshape((1, shape[0], shape[1], 1)).astype(np.float32)/quant\n","# data1 = data1 * 1.58\n","for i in range(samples-1):\n","    data[i, :, :, :] = data1[:, :, :, :]\n","    data[i, 0, :, 1] = np.sin(data1[:, 0, :, 0])\n","    data[i, 0, :, 2] = 0\n","    data[i, 0:2, :, 3] = 0\n","\n","print('data.shape:', data.shape)\n","\n","# with strategy.scope():\n","model = get_model(similarity=0.4, input_shape=(shape + (fmaps,)))\n","\n","pred = model.predict(data)\n","print('pred.shape:', pred.shape)\n","print(pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzFusApOmal2"},"source":["# 3 5x3 feature maps\n","fmaps = 4\n","shape = (5, 3)\n","samples = 1\n","quant = shape[0]*shape[1]\n","zeros = np.zeros(((1,) + shape + (fmaps,)))\n","data = np.zeros(((samples,) + shape + (fmaps,)))\n","data1 = np.arange(quant).reshape(1, shape[0], shape[1], 1).astype(np.float32)/quant\n","data1 = data1 * 1.58\n","data[0, :, :, :] = data1 \n","# data[1, :, :, :] = data1 + 1\n","# data[2, :, :, :] = data1 + 2\n","\n","for i in range(samples):\n","    data[i, :, :, :] = data1[:, :, :, :]\n","    data[i, :, :, 1] = np.sin(data1[0, :, :, 0])\n","    data[i, 0, :, 2] = 0\n","    data[i, 0:2, :, 3] = 0\n","\n","print('data.shape:', data.shape)\n","\n","    # same, sim (.466 -> 4.67)\n","# 1/3 0, (0.333 -> 0.334) \n","pruno = Pruno2D(similarity=0.47, input_shape=(shape+(fmaps,)))\n","model = tf.keras.models.Sequential(pruno)\n","model.compile()\n","model.predict(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOjb-9tf3ubb"},"source":["!!pip install -q git+https://github.com/LanceNorskog/keras-wedge.git\n","from keras_wedge_dropout import wedge_direct_comparison, wedge_normalize\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OprW5e6mAQIc","executionInfo":{"status":"ok","timestamp":1620108779587,"user_tz":420,"elapsed":6293,"user":{"displayName":"Lance N.","photoUrl":"","userId":"10641691903871358793"}},"outputId":"351ca35a-1fcc-4240-df8e-83f38ee82912"},"source":["img1 = np.asarray([[1,2],[3,4]])\n","img2 = np.asarray([[5,6],[7,3]])\n","\n","print('Feature Map #1')\n","print(img1)\n","print('Feature Map #2')\n","print(img2)\n","print()\n","\n","correlation1, percentage1 = wedge_direct_comparison(img1, img2)\n","print('Correlation (count > mean): ')\n","print(correlation1)\n","print('  similarity score:', percentage1)\n","correlation2, percentage2 = wedge_normalize(img1, img2)\n","print('Correlation (normalized and multiplied): ')\n","print(correlation2)\n","print('  similarity score:', percentage2)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Feature Map #1\n","[[1 2]\n"," [3 4]]\n","Feature Map #2\n","[[5 6]\n"," [7 3]]\n","\n","Correlation (count > mean): \n","[[ True False]\n"," [ True False]]\n","  similarity score: 0.5\n","Correlation (normalized and multiplied): \n","[[False False]\n"," [ True False]]\n","  similarity score: 0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oOkfcsw6Agdt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVkfd3ijBxWz"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"JWusauS_Bvr-"},"source":[""]}]}